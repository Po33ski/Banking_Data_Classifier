{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56adf56c",
   "metadata": {},
   "source": [
    "# Banking Data classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd0d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# gets rid of irritating warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70ac53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "banking77 = load_dataset(\"PolyAI/banking77\")\n",
    "\n",
    "df_raw_train = banking77[\"train\"].to_pandas()\n",
    "df_raw_test = banking77[\"test\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fad6ff6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "types in the train set:  text\n",
      "<class 'str'>    10003\n",
      "Name: count, dtype: int64\n",
      "types in the test set:  text\n",
      "<class 'str'>    3080\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_text_train = df_raw_train[\"text\"]\n",
    "\n",
    "print(\"types in the train set: \", df_text_train.apply(type).value_counts())\n",
    "\n",
    "df_text_test = df_raw_test[\"text\"]\n",
    "print(\"types in the test set: \", df_text_test.apply(type).value_counts())\n",
    "\n",
    "df_text_train = df_text_train.str.strip()\n",
    "df_text_test = df_text_test.str.strip()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d538c8dd",
   "metadata": {},
   "source": [
    "Manual Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e807f469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  label\n",
      "0                         I am still waiting on my card?     11\n",
      "1      What can I do if my card still hasn't arrived ...     11\n",
      "2      I have been waiting over a week. Is the card s...     11\n",
      "3      Can I track my card while it is in the process...     11\n",
      "4      How do I know if I will get my card, or if it ...     11\n",
      "...                                                  ...    ...\n",
      "9998              You provide support in what countries?     24\n",
      "9999                  What countries are you supporting?     24\n",
      "10000                What countries are getting support?     24\n",
      "10001                     Are cards available in the EU?     24\n",
      "10002                   Which countries are represented?     24\n",
      "\n",
      "[10003 rows x 2 columns]\n",
      "                                                   text  label\n",
      "0                              How do I locate my card?     11\n",
      "1     I still have not received my new card, I order...     11\n",
      "2     I ordered a card but it has not arrived. Help ...     11\n",
      "3      Is there a way to know when my card will arrive?     11\n",
      "4                          My card has not arrived yet.     11\n",
      "...                                                 ...    ...\n",
      "3075      If i'm not in the UK, can I still get a card?     24\n",
      "3076                 How many countries do you support?     24\n",
      "3077              What countries do you do business in?     24\n",
      "3078             What are the countries you operate in.     24\n",
      "3079         Can the card be mailed and used in Europe?     24\n",
      "\n",
      "[3080 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_raw_train_filtered = df_raw_train[df_raw_train[\"text\"].str.len() > 3]\n",
    "df_raw_test_filtered = df_raw_test[df_raw_test[\"text\"].str.len() > 3]\n",
    "\n",
    "df_raw_train_filtered = df_raw_train_filtered.reset_index(drop=True)\n",
    "df_raw_test_filtered = df_raw_test_filtered.reset_index(drop=True)\n",
    "\n",
    "df_raw_train_filtered = df_raw_train_filtered.drop_duplicates(subset=[\"text\"])\n",
    "df_raw_test_filtered = df_raw_test_filtered.drop_duplicates(subset=[\"text\"])\n",
    "\n",
    "df_raw_train_filtered = df_raw_train_filtered.reset_index(drop=True)\n",
    "df_raw_test_filtered = df_raw_test_filtered.reset_index(drop=True)\n",
    "\n",
    "print(df_raw_train_filtered)\n",
    "print(df_raw_test_filtered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5080f9f4",
   "metadata": {},
   "source": [
    "Cleanlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5644108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "def get_initial_model_data(texts: list[str], labels: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    # 1. Compute text embeddings with sentence-transformers\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cuda\")  # Force CPU for compatibility # for GPU use device=\"cuda\"\n",
    "    embeddings = model.encode(texts, show_progress_bar=True) #384 dimentions for each text\n",
    "    \n",
    "    # 2. Create LogisticRegression object\n",
    "    logistic_regression_model = LogisticRegression(random_state=0, C=0.1, solver='liblinear')\n",
    "    \n",
    "    # 3. Train logistic regression and get probability predictions using cross_val_predict\n",
    "    pred_probs = cross_val_predict(\n",
    "        logistic_regression_model,\n",
    "        embeddings,\n",
    "        labels,\n",
    "        cv=5,  \n",
    "        method=\"predict_proba\",  # Important: returns probabilities, not 0/1 labels\n",
    "        n_jobs=-1 \n",
    "    )\n",
    "    print(\"Cross-validation predictions computed.\")\n",
    "\n",
    "    return embeddings, pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d252ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"text\"].values\n",
    "labels = df[\"label\"].values\n",
    "\n",
    "embeddings, pred_probs = get_initial_model_data(texts, labels)\n",
    "\n",
    "# Verification\n",
    "assert len(embeddings) == len(pred_probs)\n",
    "assert pred_probs.ndim == 2\n",
    "\n",
    "print(f\"✅ Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"✅ Pred_probs shape: {pred_probs.shape}\")\n",
    "print(f\"✅ Verification passed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
